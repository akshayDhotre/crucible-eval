{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ragas Usage Demo (End-to-End)\n",
    "\n",
    "This notebook shows how to use a Crucible-generated Ragas export and run a complete evaluation loop.\n",
    "\n",
    "## What this covers\n",
    "1. Load exported `ragas` config JSON from Crucible.\n",
    "2. Generate actual answers from your app/model endpoint.\n",
    "3. Build a `datasets.Dataset`.\n",
    "4. Run Ragas metrics and inspect scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, uncomment and run once:\n",
    "# %pip install -U ragas datasets pandas requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datasets import Dataset\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Demo: Load Crucible export\n",
    "\n",
    "Set this path to the downloaded `.json` file from Crucible (output format: `ragas`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f476662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = NOTEBOOK_DIR if (NOTEBOOK_DIR / 'backend').exists() else NOTEBOOK_DIR.parent\n",
    "DOWNLOADS_DIR = PROJECT_ROOT / 'downloads'\n",
    "\n",
    "# Option 1: set explicit filename\n",
    "# RAGAS_EXPORT_PATH = DOWNLOADS_DIR / 'crucible_rag_ragas_YYYYMMDD_HHMMSS.json'\n",
    "\n",
    "# Option 2: auto-pick latest ragas export\n",
    "candidates = sorted(DOWNLOADS_DIR.glob('crucible_*_ragas_*.json'))\n",
    "RAGAS_EXPORT_PATH = candidates[-1] if candidates else DOWNLOADS_DIR / 'missing-ragas-export.json'\n",
    "\n",
    "if not RAGAS_EXPORT_PATH.exists():\n",
    "    raise FileNotFoundError(f'Update RAGAS_EXPORT_PATH first: {RAGAS_EXPORT_PATH}')\n",
    "\n",
    "raw = json.loads(RAGAS_EXPORT_PATH.read_text())\n",
    "raw.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9c419a",
   "metadata": {},
   "source": [
    "## Usage Demo: Generate real answers from your app\n",
    "\n",
    "Replace `call_app` to hit your real endpoint.\n",
    "\n",
    "Expected return shape (minimum):\n",
    "- `answer`: model/app response text\n",
    "- `contexts`: list of retrieved chunks used for the response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d8f90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_API_URL = 'http://localhost:8000/chat'  # change to your app endpoint\n",
    "\n",
    "def call_app(question: str):\n",
    "    \"\"\"\n",
    "    Replace this with your actual app call.\n",
    "    Demo supports two shapes:\n",
    "      1) {'answer': '...', 'contexts': ['...']}\n",
    "      2) plain text response (contexts fallback to empty list)\n",
    "    \"\"\"\n",
    "    resp = requests.post(APP_API_URL, json={'question': question}, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "\n",
    "    data = resp.json()\n",
    "    if isinstance(data, dict) and 'answer' in data:\n",
    "        return data.get('answer', ''), data.get('contexts', []) or []\n",
    "\n",
    "    return str(data), []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f77bed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = raw['question']\n",
    "ground_truth = raw['ground_truth']\n",
    "\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for q in questions:\n",
    "    a, c = call_app(q)\n",
    "    answers.append(a)\n",
    "    contexts.append(c if isinstance(c, list) else [str(c)])\n",
    "\n",
    "len(answers), len(contexts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8e4098",
   "metadata": {},
   "source": [
    "## Build dataset and run Ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df99a890",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'question': questions,\n",
    "    'answer': answers,\n",
    "    'contexts': contexts,\n",
    "    'ground_truth': ground_truth,\n",
    "})\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "results = evaluate(\n",
    "    dataset=dataset,\n",
    "    metrics=[faithfulness, answer_relevancy, context_precision, context_recall],\n",
    ")\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666cf02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist summary + row-level data\n",
    "summary = results.to_pandas()\n",
    "summary.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d08c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = PROJECT_ROOT / 'outputs'\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "summary_path = OUT_DIR / 'ragas_results.csv'\n",
    "summary.to_csv(summary_path, index=False)\n",
    "summary_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
