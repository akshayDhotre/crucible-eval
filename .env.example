# ── Cloud Provider Keys (fill in at least one) ────────────────────────────────
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
GOOGLE_API_KEY=

# ── Model Names (leave as-is to use defaults, or override per provider) ────────
OPENAI_MODEL_NAME=gpt-4o
ANTHROPIC_MODEL_NAME=claude-sonnet-4-6
GOOGLE_MODEL_NAME=gemini-2.0-flash
OLLAMA_MODEL_NAME=deepseek-r1

# ── Local Provider (Ollama) ───────────────────────────────────────────────────
OLLAMA_BASE_URL=http://127.0.0.1:11434

# ── Backend Config ────────────────────────────────────────────────────────────
DEFAULT_PROVIDER=openai          # used when frontend doesn't specify a provider
DEMO_MODE_ENABLED=true          # if true, falls back to ollama then static demo when no cloud key is set
LOCAL_LLM_TIMEOUT_SECONDS=120
CORS_ORIGINS=http://localhost:3000

# ── Frontend Config ───────────────────────────────────────────────────────────
NEXT_PUBLIC_API_BASE_URL=http://localhost:8000
NEXT_PUBLIC_DEFAULT_PROVIDER=openai
